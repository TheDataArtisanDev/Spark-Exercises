{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:\n",
    "+-----+------+\n",
    "|value|marker|\n",
    "+-----+------+\n",
    "|    1|     A|\n",
    "|    2|     A|\n",
    "|    3|     A|\n",
    "|    4|     A|\n",
    "|    5|     A|\n",
    "|    6|     A|\n",
    "|    7|     A|\n",
    "|    8|     A|\n",
    "|    9|     A|\n",
    "|   10|     A|\n",
    "|   11|     B|\n",
    "|   12|     B|\n",
    "|   13|     B|\n",
    "|   14|     B|\n",
    "|   15|     B|\n",
    "|   16|     B|\n",
    "|   17|     B|\n",
    "|   18|     B|\n",
    "|   19|     B|\n",
    "|   20|     B|\n",
    "+-----+------+\n",
    "\n",
    "\n",
    "Expected Output:\n",
    "+------+----+----+----+----+----+----+----+----+----+----+\n",
    "|marker|   A|   B|   C|   D|   E|   F|   G|   H|   I|   J|\n",
    "+------+----+----+----+----+----+----+----+----+----+----+\n",
    "|     B|NULL|  10|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|\n",
    "|     C|NULL|NULL|  10|NULL|NULL|NULL|NULL|NULL|NULL|NULL|\n",
    "|     A|  10|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|\n",
    "|     E|NULL|NULL|NULL|NULL|  10|NULL|NULL|NULL|NULL|NULL|\n",
    "|     D|NULL|NULL|NULL|  10|NULL|NULL|NULL|NULL|NULL|NULL|\n",
    "|     F|NULL|NULL|NULL|NULL|NULL|  10|NULL|NULL|NULL|NULL|\n",
    "|     G|NULL|NULL|NULL|NULL|NULL|NULL|  10|NULL|NULL|NULL|\n",
    "|     H|NULL|NULL|NULL|NULL|NULL|NULL|NULL|  10|NULL|NULL|\n",
    "|     J|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|  10|\n",
    "|     I|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|  10|NULL|\n",
    "+------+----+----+----+----+----+----+----+----+----+----+\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"PivotExample\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|value|marker|\n",
      "+-----+------+\n",
      "|    1|     A|\n",
      "|    2|     A|\n",
      "|    3|     A|\n",
      "|    4|     A|\n",
      "|    5|     A|\n",
      "|    6|     A|\n",
      "|    7|     A|\n",
      "|    8|     A|\n",
      "|    9|     A|\n",
      "|   10|     A|\n",
      "|   11|     B|\n",
      "|   12|     B|\n",
      "|   13|     B|\n",
      "|   14|     B|\n",
      "|   15|     B|\n",
      "|   16|     B|\n",
      "|   17|     B|\n",
      "|   18|     B|\n",
      "|   19|     B|\n",
      "|   20|     B|\n",
      "+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create sample data\n",
    "data = [\n",
    "    (1, 'A'), (2, 'A'), (3, 'A'), (4, 'A'), (5, 'A'),\n",
    "    (6, 'A'), (7, 'A'), (8, 'A'), (9, 'A'), (10, 'A'),\n",
    "    (11, 'B'), (12, 'B'), (13, 'B'), (14, 'B'), (15, 'B'),\n",
    "    (16, 'B'), (17, 'B'), (18, 'B'), (19, 'B'), (20, 'B'),\n",
    "    (21, 'C'), (22, 'C'), (23, 'C'), (24, 'C'), (25, 'C'),\n",
    "    (26, 'C'), (27, 'C'), (28, 'C'), (29, 'C'), (30, 'C'),\n",
    "    (31, 'D'), (32, 'D'), (33, 'D'), (34, 'D'), (35, 'D'),\n",
    "    (36, 'D'), (37, 'D'), (38, 'D'), (39, 'D'), (40, 'D'),\n",
    "    (41, 'E'), (42, 'E'), (43, 'E'), (44, 'E'), (45, 'E'),\n",
    "    (46, 'E'), (47, 'E'), (48, 'E'), (49, 'E'), (50, 'E'),\n",
    "    (51, 'F'), (52, 'F'), (53, 'F'), (54, 'F'), (55, 'F'),\n",
    "    (56, 'F'), (57, 'F'), (58, 'F'), (59, 'F'), (60, 'F'),\n",
    "    (61, 'G'), (62, 'G'), (63, 'G'), (64, 'G'), (65, 'G'),\n",
    "    (66, 'G'), (67, 'G'), (68, 'G'), (69, 'G'), (70, 'G'),\n",
    "    (71, 'H'), (72, 'H'), (73, 'H'), (74, 'H'), (75, 'H'),\n",
    "    (76, 'H'), (77, 'H'), (78, 'H'), (79, 'H'), (80, 'H'),\n",
    "    (81, 'I'), (82, 'I'), (83, 'I'), (84, 'I'), (85, 'I'),\n",
    "    (86, 'I'), (87, 'I'), (88, 'I'), (89, 'I'), (90, 'I'),\n",
    "    (91, 'J'), (92, 'J'), (93, 'J'), (94, 'J'), (95, 'J'),\n",
    "    (96, 'J'), (97, 'J'), (98, 'J'), (99, 'J'), (100, 'J')\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, [\"value\", \"marker\"])\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|marker|counter|\n",
      "+------+-------+\n",
      "|     B|     10|\n",
      "|     C|     10|\n",
      "|     A|     10|\n",
      "|     E|     10|\n",
      "|     D|     10|\n",
      "|     F|     10|\n",
      "|     G|     10|\n",
      "|     H|     10|\n",
      "|     J|     10|\n",
      "|     I|     10|\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as fx\n",
    "\n",
    "df1 = df.groupBy('marker').agg(fx.count('value').alias('counter'))\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----+----+----+----+----+----+----+----+----+\n",
      "|marker|   A|   B|   C|   D|   E|   F|   G|   H|   I|   J|\n",
      "+------+----+----+----+----+----+----+----+----+----+----+\n",
      "|     B|NULL|  10|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|\n",
      "|     C|NULL|NULL|  10|NULL|NULL|NULL|NULL|NULL|NULL|NULL|\n",
      "|     A|  10|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|\n",
      "|     E|NULL|NULL|NULL|NULL|  10|NULL|NULL|NULL|NULL|NULL|\n",
      "|     D|NULL|NULL|NULL|  10|NULL|NULL|NULL|NULL|NULL|NULL|\n",
      "|     F|NULL|NULL|NULL|NULL|NULL|  10|NULL|NULL|NULL|NULL|\n",
      "|     G|NULL|NULL|NULL|NULL|NULL|NULL|  10|NULL|NULL|NULL|\n",
      "|     H|NULL|NULL|NULL|NULL|NULL|NULL|NULL|  10|NULL|NULL|\n",
      "|     J|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|  10|\n",
      "|     I|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|  10|NULL|\n",
      "+------+----+----+----+----+----+----+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupBy('marker').pivot('marker').agg(fx.first('counter')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----+----+----+----+----+----+----+----+----+\n",
      "|marker|   A|   B|   C|   D|   E|   F|   G|   H|   I|   J|\n",
      "+------+----+----+----+----+----+----+----+----+----+----+\n",
      "|     B|NULL|  10|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|\n",
      "|     C|NULL|NULL|  10|NULL|NULL|NULL|NULL|NULL|NULL|NULL|\n",
      "|     A|  10|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|\n",
      "|     E|NULL|NULL|NULL|NULL|  10|NULL|NULL|NULL|NULL|NULL|\n",
      "|     D|NULL|NULL|NULL|  10|NULL|NULL|NULL|NULL|NULL|NULL|\n",
      "|     F|NULL|NULL|NULL|NULL|NULL|  10|NULL|NULL|NULL|NULL|\n",
      "|     G|NULL|NULL|NULL|NULL|NULL|NULL|  10|NULL|NULL|NULL|\n",
      "|     H|NULL|NULL|NULL|NULL|NULL|NULL|NULL|  10|NULL|NULL|\n",
      "|     J|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|  10|\n",
      "|     I|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|  10|NULL|\n",
      "+------+----+----+----+----+----+----+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('marker').pivot('marker').agg(fx.count('value').alias('counter')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('temp_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+---+---+---+\n",
      "|  A|  B|  C|  D|  E|  F|  G|  H|  I|  J|\n",
      "+---+---+---+---+---+---+---+---+---+---+\n",
      "| 10| 10| 10| 10| 10| 10| 10| 10| 10| 10|\n",
      "+---+---+---+---+---+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 =  spark.sql(\"\"\"\n",
    "        select * from \n",
    "          (select value, marker from temp_df)\n",
    "        pivot(count(value) for marker in ('A','B','C','D','E','F','G','H','I','J'))\n",
    "\"\"\")\n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
